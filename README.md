# Dataset
here are 2 datasets of audios, the first one is the the English dataset which is all the files expect the arabic_fake and arabic_real
to create the first dataset and use it download all the audios and compine them in a file then use 90% of these audios as a training set (20% of it is validation which the model take without the need to do it manually) while the remaining 10% for testing

the Arbic dataset is by compining the files with the English that you already have to create the mixed dataset and as before 90% is for training (20% of it is validation which the model take without the need to do it manually) and 10% for testing



NOTE:
to know the real and fake audios during tarining the audios that ends with 'r' are real and the one ands with 'f' are fake
